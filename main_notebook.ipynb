{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6wSoO0rYeHu1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6joVRAQ5gLKZ"
      },
      "outputs": [],
      "source": [
        "def embedding(data, y, num_classes):\n",
        "    input = data.clone().detach()\n",
        "    one_hot = F.one_hot(y, num_classes=num_classes)\n",
        "    input[:,:,0,:num_classes] = one_hot.view(one_hot.shape[0], 1, one_hot.shape[1])\n",
        "    return input\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, images, labels, size=(28, 28), num_classes=10, transforms=None, train=True):\n",
        "        self.X = images\n",
        "        self.y = labels\n",
        "\n",
        "        self.w = size[0]\n",
        "        self.h = size[1]\n",
        "\n",
        "        if transforms is not None:\n",
        "            self.transforms = transforms\n",
        "        else:\n",
        "            self.transforms = torchvision.transforms.Compose(\n",
        "                                  [\n",
        "                                  torchvision.transforms.ToPILImage(),\n",
        "                                  torchvision.transforms.ToTensor(),\n",
        "                                  torchvision.transforms.Normalize((0.5, ), (0.5, ))\n",
        "                              ])\n",
        "            \n",
        "        self.train = train\n",
        "         \n",
        "    def __len__(self):\n",
        "        return (len(self.X))\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        data = self.X.iloc[i, :]\n",
        "        data = np.asarray(data).astype(np.uint8).reshape(self.h, self.w, 1)\n",
        "        \n",
        "        if self.transforms:\n",
        "            data = self.transforms(data)\n",
        "\n",
        "        return data, self.y[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e1hlhIthmlde"
      },
      "outputs": [],
      "source": [
        "class FFLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features,\n",
        "                 num_epochs = 1000, bias=True):\n",
        "        super(FFLinear, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(in_features = in_features, \n",
        "                                out_features = out_features, \n",
        "                                bias = bias)\n",
        "        \n",
        "        nn.init.xavier_uniform_(self.linear.weight.data, gain=1.0)\n",
        "        nn.init.zeros_(self.linear.bias.data)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.optimizer = torch.optim.Adam(self.linear.parameters(), lr=0.03)\n",
        "        self.threshold = 2.0\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = x.norm(2, 1, keepdim=True)\n",
        "        x_dir = x / (x_norm + 1e-4)\n",
        "        res = self.linear(x_dir)\n",
        "        return self.relu(res)\n",
        "\n",
        "    def forward_forward(self, x_pos, x_neg):\n",
        "\n",
        "        for i in range(self.num_epochs):\n",
        "            x_pos.requires_grad = True\n",
        "            x_neg.requires_grad = True\n",
        "\n",
        "            g_pos = torch.mean(torch.pow(self.forward(x_pos), 2), 1)\n",
        "            g_neg = torch.mean(torch.pow(self.forward(x_neg), 2), 1)\n",
        "\n",
        "            loss = self.criterion(g_pos, g_neg)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            \n",
        "        with torch.no_grad():\n",
        "            return self.forward(x_pos), self.forward(x_neg), loss\n",
        "\n",
        "    def criterion(self, g_pos, g_neg):\n",
        "        return torch.mean(\n",
        "            torch.log(\n",
        "                1 + torch.exp(torch.cat([-g_pos + self.threshold, g_neg - self.threshold], 0))\n",
        "            )\n",
        "        )\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "40ioUVVNTnMy"
      },
      "outputs": [],
      "source": [
        "class FFNetwork(nn.Module):\n",
        "    def __init__(self, in_features=784, num_classes=10):\n",
        "        super(FFNetwork, self).__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.ff_1 = FFLinear(in_features=self.in_features, out_features=512)\n",
        "        self.ff_2 = FFLinear(in_features=512, out_features=512)\n",
        "        self.ff_3 = FFLinear(in_features=512, out_features=512)\n",
        "        self.ff_4 = FFLinear(in_features=512, out_features=512)\n",
        "\n",
        "        self.layers = [self.ff_1, self.ff_2, self.ff_3, self.ff_4]\n",
        "\n",
        "    def train(self, data_pos, data_neg):\n",
        "        h_pos = data_pos.view(-1, self.in_features)\n",
        "        h_neg = data_neg.view(-1, self.in_features)\n",
        "\n",
        "        total_loss = 0\n",
        "        total_cnt = 0\n",
        "\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            if isinstance(layer, FFLinear):\n",
        "                print(f\"Training layer {idx+1} now\")\n",
        "                h_pos, h_neg, loss = layer.forward_forward(h_pos, h_neg)\n",
        "                \n",
        "                total_loss += loss\n",
        "                total_cnt += 1\n",
        "\n",
        "            else:\n",
        "                print(f\"Passing layer {idx+1} now\")\n",
        "                x = layer(x)\n",
        "\n",
        "        print('Loss: ', total_loss / total_cnt)\n",
        "\n",
        "    def predict(self, data):\n",
        "        with torch.no_grad():\n",
        "            goodness_per_label = []\n",
        "            for cls in range(self.num_classes):\n",
        "                lbl = torch.tensor([cls] * data.shape[0])\n",
        "                input = embedding(data, lbl, self.num_classes)\n",
        "\n",
        "                h = input.view(-1, self.in_features)\n",
        "\n",
        "                goodness = []\n",
        "                for layer in self.layers:\n",
        "                    h = layer(h)\n",
        "                    goodness += [h.pow(2).mean(1)]\n",
        "                goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
        "\n",
        "            goodness_per_label = torch.cat(goodness_per_label, 1)\n",
        "            return goodness_per_label.argmax(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N5Rxr8CMUHPx"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "batch_size = 10000\n",
        "\n",
        "df_train = pd.read_csv('./sample_data/mnist_train_small.csv', header=None)\n",
        "df_test = pd.read_csv('./sample_data/mnist_test.csv', header=None)\n",
        "\n",
        "train_labels = df_train.iloc[:, 0]\n",
        "train_images = df_train.iloc[:, 1:]\n",
        "test_labels = df_test.iloc[:, 0]\n",
        "test_images = df_test.iloc[:, 1:]\n",
        "\n",
        "custom_transform = torchvision.transforms.Compose(\n",
        "                    [\n",
        "                    torchvision.transforms.ToPILImage(),\n",
        "                    torchvision.transforms.ToTensor(),\n",
        "                    torchvision.transforms.Normalize((0.5, ), (0.5, ))\n",
        "                ])\n",
        "\n",
        "train_data = MNISTDataset(train_images, train_labels, transforms=custom_transform)\n",
        "test_data = MNISTDataset(test_images, test_labels, transforms=custom_transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "\n",
        "model = FFNetwork().cuda() if torch.cuda.is_available() else FFNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o7sqGPngD6J",
        "outputId": "b0766461-4386-4d8f-ae28-53f3858260d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "Training layer 1 now\n",
            "Training layer 2 now\n",
            "Training layer 3 now\n",
            "Training layer 4 now\n",
            "Loss:  tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training layer 1 now\n",
            "Training layer 2 now\n",
            "Training layer 3 now\n",
            "Training layer 4 now\n",
            "Loss:  tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(\"Start training...\")\n",
        "for data, lbl in train_loader:\n",
        "\n",
        "    data_pos = data.clone().detach()\n",
        "    lbl_pos = lbl.clone().detach()\n",
        "    data_pos = embedding(data_pos, lbl, num_classes=num_classes)\n",
        "    \n",
        "    data_neg = data.clone().detach()\n",
        "    lbl_neg = torch.from_numpy(np.random.choice(num_classes, data.shape[0]))\n",
        "    data_neg = embedding(data_neg, lbl_neg, num_classes=num_classes)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        data_pos, data_neg = data_pos.cuda(), data_neg.cuda()\n",
        "\n",
        "    model.train(data_pos, data_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryFtoUzWgD8b",
        "outputId": "f2f03ccb-0d60-4817-dfce-d44a4c5e96d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start testing...\n",
            "F1-score:  0.9109228917932397\n"
          ]
        }
      ],
      "source": [
        "print(\"Start testing...\")\n",
        "predictions = []\n",
        "groundtruths = []\n",
        "\n",
        "for i, (data_test, lbl_test) in enumerate(test_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        data_test = data_test.cuda()\n",
        "\n",
        "    prediction = model.predict(data_test).item()\n",
        "    groundtruth = lbl_test.item()\n",
        "\n",
        "    predictions.append(prediction)\n",
        "    groundtruths.append(groundtruth)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"F1-score: \", f1_score(groundtruths, predictions, average='macro'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12 (main, Jun  1 2022, 06:34:44) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d61e67d4406f83661a218a7594034be74564666d0640d3900a3e99845865d0f0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
